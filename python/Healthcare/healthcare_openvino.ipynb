{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Segmentation (BraTS) with OpenVINO™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code example, we apply the U-Net architecture to segment brain tumors from raw MRI scans. With relatively little data we are able to train a U-Net model to accurately predict where tumors exist. \n",
    "\n",
    "The Dice coefficient (the standard metric for the BraTS dataset used in the study) for our model is about 0.82-0.88.  Menze et al. [reported](http://ieeexplore.ieee.org/document/6975210/) that expert neuroradiologists manually segmented these tumors with a cross-rater Dice score of 0.75-0.85, meaning that the model’s predictions are on par with what expert physicians have made. The below MRI brain scans highlight brain tumor matter segmented using deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/figure1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration objectives\n",
    "* Healthcare use-case demo\n",
    "* **Model Optimizer** in action\n",
    "* U-Net based segmentation on edge hardware\n",
    "* Inferencing with OpenVINO™ Inference Engine\n",
    "* Running inference across CPU, integrated GPU, VPU, and FPGA and comparing throughput and latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is U-Net?\n",
    "Since its introduction two years ago, the [U-Net](https://arxiv.org/pdf/1505.04597.pdf0) architecture has been used to create deep learning models for segmenting [nerves](https://github.com/jocicmarko/ultrasound-nerve-segmentation) in ultrasound images, [lungs](https://www.kaggle.com/c/data-science-bowl-2017#tutorial) in CT scans, and even [interference](https://github.com/jakeret/tf_unet) in radio telescopes.\n",
    "\n",
    "U-Net is designed like an [auto-encoder](https://en.wikipedia.org/wiki/Autoencoder). It has an encoding path (“contracting”) paired with a decoding path (“expanding”) which gives it the “U” shape.  However, in contrast to the autoencoder, U-Net predicts a pixelwise segmentation map of the input image rather than classifying the input image as a whole. For each pixel in the original image, it asks the question: “To which class does this pixel belong?” This flexibility allows U-Net to predict different parts of the tumor simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/unet.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Set Up\n",
    "\n",
    "### 0.1: Import dependencies\n",
    "\n",
    "Run the below cells to import dependencies (select the cell and use **Ctrl+enter** to run the cell). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os \n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent))\n",
    "from demoTools.demoutils import *\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first time you run this notebook this step will take a few minutes, as we will be installing `keras` and `psutil` locally to your instance in the DevCloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import keras\n",
    "except:\n",
    "    print(\"Keras not installed\")\n",
    "    !{sys.executable} -m pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import psutil\n",
    "except:\n",
    "    print(\"psutil not installed\")\n",
    "    !{sys.executable} -m pip install psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Create an Intermediate Representation (IR) Model using the Model Optimizer by Intel\n",
    "\n",
    "The Model Optimizer creates Intermediate Representation (IR) models that are optimized for different end-point target devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Generate FP32 Optimized Model\n",
    "Now, let's convert the model to the optimized model using the model optimizer. This model works best on most hardware, including CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py \\\n",
    "            --input_model /data/Healthcare_app/data/saved_model_frozen.pb \\\n",
    "            --input_shape=[1,144,144,4] \\\n",
    "            --data_type FP32  \\\n",
    "            --output_dir output/IR_models/FP32  \\\n",
    "            --model_name saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** the above line is a single command line input, which spans 4 lines thanks to the backslash '\\\\', which is a line continuation character in Bash.\n",
    "\n",
    "Here, the arguments are:\n",
    "* --input-model : the original model\n",
    "* --data_type : Data type to use. One of {FP32, FP16, half, float}\n",
    "* -o : output directory (If this directory does not exist, it will be created for you.)\n",
    "\n",
    "This script also supports `-h` that will you can get the full list of arguments.\n",
    "\n",
    "Running that command will produce two files:\n",
    "```\n",
    "output/IR_models/FP32/saved_model.xml\n",
    "output/IR_models/FP32/saved_model.bin\n",
    "```\n",
    "These will be used later in the exercise.\n",
    "\n",
    "### 1.2: Generate FP16 Optimized Model\n",
    "\n",
    "We will also be needing the FP16 version of the model for the calculations on the VPU architecture. Run the following command to create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py \\\n",
    "            --input_model /data/Healthcare_app/data/saved_model_frozen.pb  \\\n",
    "            --input_shape=[1,144,144,4] \\\n",
    "            --data_type FP16  \\\n",
    "            --output_dir output/IR_models/FP16  \\\n",
    "            --model_name saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile healthcare_job_openvino.sh\n",
    "\n",
    "# Prevent error and output files from being saved to DevCloud\n",
    "#PBS -e /dev/null\n",
    "\n",
    "cd $PBS_O_WORKDIR\n",
    "DEVICE=$1\n",
    "RESULTS=$2\n",
    "\n",
    "if [ \"$DEVICE\" = \"HETERO:FPGA,CPU\" ]; then\n",
    "    # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/opt/altera/aocl-pro-rte/aclrte-linux64/\n",
    "    source /opt/intel/init_openvino.sh\n",
    "    aocl program acl0 /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/2019R3_PV_PL1_FP11_ResNet_VGG.aocx\n",
    "fi\n",
    "\n",
    "if [ \"$DEVICE\" = \"MYRIAD\" ] || [ \"$DEVICE\" = \"HDDL\" ]; then\n",
    "    FP_MODEL=\"FP16\"\n",
    "else\n",
    "    FP_MODEL=\"FP32\"\n",
    "fi\n",
    "\n",
    "    \n",
    "# Running the object detection code\n",
    "SAMPLEPATH=$PBS_O_WORKDIR\n",
    "python3 healthcare_openvino.py     -d $DEVICE \\\n",
    "                                   -IR output/IR_models/${FP_MODEL}/saved_model \\\n",
    "                                   -l /opt/intel/openvino/inference_engine/lib/intel64/libcpu_extension_avx2.so \\\n",
    "                                   -r $RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Inference Time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create job files and submit them to different edge compute nodes. They will go into a queue and run once the compute resources are available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with an Intel® CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank* 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel® Core™ i5-6500TE processor</a>. The inference workload will run the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_core = !qsub healthcare_job_openvino.sh -l nodes=1:idc001skl:tank-870:i5-6500te  -F \"CPU results/\"\n",
    "print(job_id_core[0]) \n",
    "if job_id_core:\n",
    "    progressIndicator('results/'+job_id_core[0], 'i_progress.txt', \"Processing\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Xeon® CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank* 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88178/Intel-Xeon-Processor-E3-1268L-v5-8M-Cache-2-40-GHz-\">Intel® \n",
    "    Xeon® Processor E3-1268L v5</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_xeon = !qsub healthcare_job_openvino.sh -l nodes=1:idc007xv5:e3-1268l-v5  -F \"CPU results/\"\n",
    "print(job_id_xeon[0]) \n",
    "if job_id_xeon:\n",
    "    progressIndicator('results/'+job_id_xeon[0], 'i_progress.txt', \"Processing\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Core CPU and using the onboard Intel® GPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank* 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel® Core i5-6500TE</a>. The inference workload will run on the Intel® HD Graphics 530 card integrated with the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub healthcare_job_openvino.sh -l nodes=1:idc001skl:intel-hd-530 -F \"GPU results/\"\n",
    "print(job_id_gpu) \n",
    "if job_id_gpu:\n",
    "    progressIndicator('results/'+job_id_gpu[0], 'i_progress.txt', \"Processing\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® NCS 2 (Neural Compute Stick 2)\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a>. The inference workload will run on an <a \n",
    "    href=\"https://software.intel.com/en-us/neural-compute-stick\">Intel Neural Compute Stick 2</a> installed in this  node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_ncs2 = !qsub healthcare_job_openvino.sh -l nodes=1:idc004nc2:intel-ncs2 -F \"MYRIAD results/\"\n",
    "print(job_id_ncs2[0]) \n",
    "if job_id_ncs2:\n",
    "    progressIndicator('results/'+job_id_ncs2[0], 'i_progress.txt', \"Processing\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core™ i5-6500te CPU</a> . The inference workload will run on the <a href=\"https://www.ieiworld.com/mustang-f100/en/\"> IEI Mustang-F100-A10 </a> card installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_fpga = !qsub healthcare_job_openvino.sh -l nodes=1:idc003a10:iei-mustang-f100-a10 -F \"HETERO:FPGA,CPU results/\"\n",
    "print(job_id_fpga[0]) \n",
    "if job_id_fpga:\n",
    "    progressIndicator('results/'+job_id_fpga[0], 'i_progress.txt', \"Processing\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the status of the jobs below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveQstat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Image Comparison\n",
    "Here, we visualize our predictions. We can observe the frame rate, execution time, and dice coefficient (a value that describes the similarity between the ground truth and the prediction, with 1.0 indicating 100% accuracy). Note that it may take a few seconds to display the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputHTML('IEI Tank (Intel Core CPU)',\n",
    "          'results/'+job_id_core[0], '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputHTML('IEI Tank Xeon (Intel Xeon CPU)',\n",
    "          'results/'+job_id_xeon[0], '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputHTML('IEI Intel GPU (Intel Core + Onboard GPU)',\n",
    "          'results/'+job_id_gpu[0], '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputHTML('IEI Tank + Intel CPU + Intel NCS2',\n",
    "          'results/'+job_id_ncs2[0], '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputHTML('IEI Tank + IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)',\n",
    "          'results/'+job_id_fpga[0], '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Architecture Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we benchmark the processing time and frames per second on different architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_list = [('core', 'Intel Core\\ni5-6500TE\\nCPU'),\n",
    "             ('xeon', 'Intel Xeon\\nE3-1268L v5\\nCPU'),\n",
    "             ('gpu', ' Intel Core\\ni5-6500TE\\nGPU'),\n",
    "             ('ncs2', 'Intel\\nNCS2'),\n",
    "             ('fpga', 'IEI Mustang\\nF100-A10\\nFPGA')\n",
    "            ]\n",
    "\n",
    "stats_list = []\n",
    "for arch, a_name in arch_list:\n",
    "    if 'job_id_'+arch in vars():\n",
    "        stats_list.append(('results/'+vars()['job_id_'+arch][0]+'/stats.txt', a_name))\n",
    "    else:\n",
    "        stats_list.append(('placeholder'+arch, a_name))\n",
    "\n",
    "summaryPlot(stats_list, 'Architecture', 'Time, seconds', 'Inference Engine Processing Time', 'time' )\n",
    "\n",
    "summaryPlot(stats_list, 'Architecture', 'Frames per second', 'Inference Engine FPS', 'fps' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
